{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training dataset\n",
      "87 108\n",
      "0.8055555555555556\n",
      "87 108\n",
      "0.8055555555555556\n",
      "91 108\n",
      "0.8425925925925926\n",
      "93 108\n",
      "0.8611111111111112\n",
      "91 108\n",
      "0.8425925925925926\n",
      "95 108\n",
      "0.8796296296296297\n",
      "95 108\n",
      "0.8796296296296297\n",
      "90 108\n",
      "0.8333333333333334\n",
      "94 108\n",
      "0.8703703703703703\n",
      "93 108\n",
      "0.8611111111111112\n",
      "91 108\n",
      "0.8425925925925926\n",
      "89 108\n",
      "0.8240740740740741\n",
      "94 108\n",
      "0.8703703703703703\n",
      "94 108\n",
      "0.8703703703703703\n",
      "91 108\n",
      "0.8425925925925926\n",
      "94 108\n",
      "0.8703703703703703\n",
      "97 108\n",
      "0.8981481481481481\n",
      "92 108\n",
      "0.8518518518518519\n",
      "96 108\n",
      "0.8888888888888888\n",
      "92 108\n",
      "0.8518518518518519\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Nov 16 01:29:58 2017\n",
    "\n",
    "@author: User\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from sklearn.neural_network import MLPClassifier   \n",
    "from sklearn.model_selection import train_test_split\n",
    "config = tf.ConfigProto()\n",
    "from sklearn.svm import SVC\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "with tf.Session(config = config) as s:\n",
    "\n",
    "    import numpy\n",
    "    from keras.datasets import mnist\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import Dropout\n",
    "    from keras.layers import Flatten\n",
    "    from keras.layers.convolutional import Conv2D\n",
    "    from keras.layers.convolutional import MaxPooling2D\n",
    "    from keras.utils import np_utils\n",
    "    from keras import backend as K\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from keras.models import model_from_json\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    K.set_image_dim_ordering('th')\n",
    "    \n",
    "    seed = 7\n",
    "    numpy.random.seed(seed)\n",
    "    \n",
    "    dataset = numpy.loadtxt(\"E:\\\\Course\\\\Semester_4_1\\\\ML_LAB\\\\Signature_Data\\\\our\\\\out_24.txt\",delimiter=\",\")\n",
    "    print('loaded training dataset')\n",
    "    dim = 100*200\n",
    "    count=0\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    X.clear()\n",
    "    Y.clear()\n",
    "    for i in dataset:\n",
    "        X.append([])\n",
    "        for j in range(dim):\n",
    "            X[count].append(i[j])\n",
    "        value=int(i[dim])\n",
    "        if(count<=240):\n",
    "            if(value>=1000):\n",
    "                Y.append(int(value/100))\n",
    "            elif(value>=100):\n",
    "                Y.append(int(value/10))\n",
    "            else :\n",
    "                Y.append(int(value/10))\n",
    "        else :\n",
    "            if(value>=100):\n",
    "                Y.append(int(value/100))\n",
    "            else :\n",
    "                Y.append(int(value/10))\n",
    "        count+=1\n",
    "   # X_train, X_test, y_train , y_test = train_test_split(X, Y,shuffle = True,test_size = 0.1)\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "        #X1.append((X[row]))\n",
    "        #print(X_train)\n",
    "        #Y1.append((float)(Y[row]))\n",
    "    dataset = numpy.loadtxt(\"E:\\\\Course\\\\Semester_4_1\\\\ML_LAB\\\\Signature_Data\\\\our\\\\out_6.txt\",delimiter=\",\")\n",
    "    y_test=[]\n",
    "    X_test=[]\n",
    "    count=0\n",
    "    for i in dataset:\n",
    "        X_test.append([])\n",
    "        for j in range(dim):\n",
    "            X_test[count].append(i[j])\n",
    "        value=int(i[dim])\n",
    "        if(count<=60):\n",
    "            if(value>=1000):\n",
    "                y_test.append(int(value/100))\n",
    "            elif(value>=100):\n",
    "                y_test.append(int(value/10))\n",
    "            else :\n",
    "                y_test.append(int(value/10))\n",
    "        else :\n",
    "            if(value>=100):\n",
    "                y_test.append(int(value/100))\n",
    "            else :\n",
    "                y_test.append(int(value/10))\n",
    "        count+=1\n",
    "    for i in range(20):\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(35,i+25), random_state=1)\n",
    "\n",
    "\n",
    "        clf.fit(X,Y)\n",
    "        count=0\n",
    "        prediction = clf.predict(X_test)\n",
    "        for i in range(len(prediction)):\n",
    "            if(prediction[i]==y_test[i]):\n",
    "                count+=1\n",
    "            #print(str(prediction[i])+\" \"+str(y_test[i])+\"\\n\")\n",
    "        #print(X_train.shape , X_test.shape)\n",
    "       # X_train = X_train.reshape(X_train.shape[0], 1, 100, 200).astype('float32')\n",
    "        #X_test = X_test.reshape(X_test.shape[0], 1, 100, 200).astype('float32')\n",
    "        print(str(count)+\" \"+str(len(prediction)))\n",
    "        print((count/len(prediction)))\n",
    "\n",
    "        #yy = y_test\n",
    "        #y_train = np_utils.to_categorical(y_train)\n",
    "       # y_test = np_utils.to_categorical(y_test)\n",
    "        #num_classes = y_test.shape[1]\n",
    "       # print(num_classes)\n",
    "    \n",
    "    \n",
    "    #print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training dataset\n",
      "14 87\n",
      "70 87\n",
      "78 87\n",
      "82 87\n",
      "82 87\n",
      "79 87\n",
      "81 87\n",
      "82 87\n",
      "82 87\n",
      "82 87\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Nov 16 01:29:58 2017\n",
    "\n",
    "@author: User\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from sklearn.neural_network import MLPClassifier   \n",
    "from sklearn.model_selection import train_test_split\n",
    "config = tf.ConfigProto()\n",
    "from sklearn.svm import SVC\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "with tf.Session(config = config) as s:\n",
    "\n",
    "    import numpy\n",
    "    from keras.datasets import mnist\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import Dropout\n",
    "    from keras.layers import Flatten\n",
    "    from keras.layers.convolutional import Conv2D\n",
    "    from keras.layers.convolutional import MaxPooling2D\n",
    "    from keras.utils import np_utils\n",
    "    from keras import backend as K\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from keras.models import model_from_json\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    K.set_image_dim_ordering('th')\n",
    "    \n",
    "\n",
    " \n",
    "    \n",
    "    dataset = numpy.loadtxt(\"E:\\\\Course\\\\Semester_4_1\\\\ML_LAB\\\\Signature_Data\\\\our\\\\out_24.txt\",delimiter=\",\")\n",
    "    print('loaded training dataset')\n",
    "    dim = 100*200\n",
    "    count=0\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for i in dataset:\n",
    "        X.append([])\n",
    "        for j in range(dim):\n",
    "            X[count].append(i[j])\n",
    "        value=int(i[dim])\n",
    "        if(count<=240):\n",
    "            if(value>=1000):\n",
    "                Y.append(int(value/100))\n",
    "            elif(value>=100):\n",
    "                Y.append(int(value/10))\n",
    "            else :\n",
    "                Y.append(int(value/10))\n",
    "        else :\n",
    "            if(value>=100):\n",
    "                Y.append(int(value/100))\n",
    "            else :\n",
    "                Y.append(int(value/10))\n",
    "        count+=1\n",
    "   # X_train, X_test, y_train , y_test = train_test_split(X, Y,shuffle = True,test_size = 0.1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "        #X1.append((X[row]))\n",
    "        #print(X_train)\n",
    "        #Y1.append((float)(Y[row]))\n",
    "    for i in range(10): \n",
    "        clf= SVC(kernel = 'rbf', C = i+1).fit(X_train, y_train)\n",
    "        prediction = clf.predict(X_test)\n",
    "        count=0\n",
    "        for i in range(len(prediction)):\n",
    "            if(prediction[i]==y_test[i]):\n",
    "                count+=1\n",
    "            #print(str(prediction[i])+\" \"+str(y_test[i])+\"\\n\")\n",
    "        #print(X_train.shape , X_test.shape)\n",
    "       # X_train = X_train.reshape(X_train.shape[0], 1, 100, 200).astype('float32')\n",
    "        #X_test = X_test.reshape(X_test.shape[0], 1, 100, 200).astype('float32')\n",
    "        print(str(count)+\" \"+str(len(prediction)))\n",
    "\n",
    "        #yy = y_test\n",
    "        #y_train = np_utils.to_categorical(y_train)\n",
    "       # y_test = np_utils.to_categorical(y_test)\n",
    "        #num_classes = y_test.shape[1]\n",
    "       # print(num_classes)\n",
    "    \n",
    "    \n",
    "    #print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training dataset\n",
      "432\n",
      "432\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-f8fe0cd24ba5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshrinking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    574\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Nov 16 01:29:58 2017\n",
    "\n",
    "@author: User\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from sklearn.neural_network import MLPClassifier   \n",
    "from sklearn.model_selection import train_test_split\n",
    "config = tf.ConfigProto()\n",
    "from sklearn.svm import SVC\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "with tf.Session(config = config) as s:\n",
    "\n",
    "    import numpy\n",
    "    from keras.datasets import mnist\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import Dropout\n",
    "    from keras.layers import Flatten\n",
    "    from keras.layers.convolutional import Conv2D\n",
    "    from keras.layers.convolutional import MaxPooling2D\n",
    "    from keras.utils import np_utils\n",
    "    from keras import backend as K\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from keras.models import model_from_json\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    K.set_image_dim_ordering('th')\n",
    "    \n",
    "\n",
    " \n",
    "    \n",
    "    dataset = numpy.loadtxt(\"E:\\\\Course\\\\Semester_4_1\\\\ML_LAB\\\\Signature_Data\\\\our\\\\out_24.txt\",delimiter=\",\")\n",
    "    print('loaded training dataset')\n",
    "    dim = 100*200\n",
    "    count=0\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    X.clear()\n",
    "    Y.clear()\n",
    "    for i in dataset:\n",
    "        X.append([])\n",
    "        for j in range(dim):\n",
    "            X[count].append(i[j])\n",
    "        value=int(i[dim])\n",
    "        if(count<=240):\n",
    "            if(value>=1000):\n",
    "                Y.append(int(value/100))\n",
    "            elif(value>=100):\n",
    "                Y.append(int(value/10))\n",
    "            else :\n",
    "                Y.append(int(value/10))\n",
    "        else :\n",
    "            if(value>=100):\n",
    "                Y.append(int(value/100))\n",
    "            else :\n",
    "                Y.append(int(value/10))\n",
    "    dataset = numpy.loadtxt(\"E:\\\\Course\\\\Semester_4_1\\\\ML_LAB\\\\Signature_Data\\\\our\\\\out_6.txt\",delimiter=\",\")\n",
    "    y_test=[]\n",
    "    X_test=[]\n",
    "    count=0\n",
    "    for i in dataset:\n",
    "        X_test.append([])\n",
    "        for j in range(dim):\n",
    "            X_test[count].append(i[j])\n",
    "        value=int(i[dim])\n",
    "        if(count<=60):\n",
    "            if(value>=1000):\n",
    "                y_test.append(int(value/100))\n",
    "            elif(value>=100):\n",
    "                y_test.append(int(value/10))\n",
    "            else :\n",
    "                y_test.append(int(value/10))\n",
    "        else :\n",
    "            if(value>=100):\n",
    "                y_test.append(int(value/100))\n",
    "            else :\n",
    "                y_test.append(int(value/10))\n",
    "        count+=1\n",
    "    print(len(X))\n",
    "    print(len(Y))\n",
    "    clf= SVC( kernel='rbf', C = 4.0, class_weight=None,degree=3, gamma='auto',random_state=None, shrinking=True,).fit(X, Y)\n",
    "    prediction = clf.predict(X_test)\n",
    "    count=0\n",
    "    for i in range(len(prediction)):\n",
    "        if(prediction[i]==y_test[i]):\n",
    "            count+=1\n",
    "        #print(str(prediction[i])+\" \"+str(y_test[i])+\"\\n\")\n",
    "    #print(X_train.shape , X_test.shape)\n",
    "   # X_train = X_train.reshape(X_train.shape[0], 1, 100, 200).astype('float32')\n",
    "    #X_test = X_test.reshape(X_test.shape[0], 1, 100, 200).astype('float32')\n",
    "    print(str(count)+\" \"+str(len(prediction)))\n",
    "    print((count/len(prediction)))\n",
    "    #yy = y_test\n",
    "    #y_train = np_utils.to_categorical(y_train)\n",
    "   # y_test = np_utils.to_categorical(y_test)\n",
    "        #num_classes = y_test.shape[1]\n",
    "       # print(num_classes)\n",
    "    \n",
    "    \n",
    "    #print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "dataset = numpy.loadtxt(\"E:\\\\Course\\\\Semester_4_1\\\\ML_LAB\\\\Signature_Data\\\\our\\\\out_24.txt\",delimiter=\",\")\n",
    "print('loaded training dataset')\n",
    "dim = 100*200\n",
    "count=0\n",
    "X=[]\n",
    "Y=[]\n",
    "X.clear()\n",
    "Y.clear()\n",
    "for i in dataset:\n",
    "    X.append([])\n",
    "    for j in range(dim):\n",
    "        X[count].append(i[j])\n",
    "    value=int(i[dim])\n",
    "    if(count<=240):\n",
    "        if(value>=1000):\n",
    "            Y.append(int(value/100))\n",
    "        elif(value>=100):\n",
    "            Y.append(int(value/10))\n",
    "        else :\n",
    "            Y.append(int(value/10))\n",
    "    else :\n",
    "        if(value>=100):\n",
    "            Y.append(int(value/100))\n",
    "        else :\n",
    "            Y.append(int(value/10))\n",
    "dataset = numpy.loadtxt(\"E:\\\\Course\\\\Semester_4_1\\\\ML_LAB\\\\Signature_Data\\\\our\\\\out_6.txt\",delimiter=\",\")\n",
    "y_test=[]\n",
    "X_test=[]\n",
    "count=0\n",
    "for i in dataset:\n",
    "    X_test.append([])\n",
    "    for j in range(dim):\n",
    "        X_test[count].append(i[j])\n",
    "    value=int(i[dim])\n",
    "    if(count<=60):\n",
    "        if(value>=1000):\n",
    "            y_test.append(int(value/100))\n",
    "        elif(value>=100):\n",
    "            y_test.append(int(value/10))\n",
    "        else :\n",
    "            y_test.append(int(value/10))\n",
    "    else :\n",
    "        if(value>=100):\n",
    "            y_test.append(int(value/100))\n",
    "        else :\n",
    "            y_test.append(int(value/10))\n",
    "    count+=1\n",
    "reg.fit(X,Y)\n",
    "acc=reg.score(X_test,y_test)\n",
    "print(\"Accuracy %.2f\" % round(acc*100,2)+' %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
