{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MDAK\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training dataset\n",
      "87 108\n",
      "0.8055555555555556\n",
      "87 108\n",
      "0.8055555555555556\n",
      "91 108\n",
      "0.8425925925925926\n",
      "93 108\n",
      "0.8611111111111112\n",
      "91 108\n",
      "0.8425925925925926\n",
      "95 108\n",
      "0.8796296296296297\n",
      "95 108\n",
      "0.8796296296296297\n",
      "90 108\n",
      "0.8333333333333334\n",
      "94 108\n",
      "0.8703703703703703\n",
      "93 108\n",
      "0.8611111111111112\n",
      "91 108\n",
      "0.8425925925925926\n",
      "89 108\n",
      "0.8240740740740741\n",
      "94 108\n",
      "0.8703703703703703\n",
      "94 108\n",
      "0.8703703703703703\n",
      "91 108\n",
      "0.8425925925925926\n",
      "94 108\n",
      "0.8703703703703703\n",
      "97 108\n",
      "0.8981481481481481\n",
      "92 108\n",
      "0.8518518518518519\n",
      "96 108\n",
      "0.8888888888888888\n",
      "92 108\n",
      "0.8518518518518519\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Nov 16 01:29:58 2017\n",
    "\n",
    "@author: User\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from sklearn.neural_network import MLPClassifier   \n",
    "from sklearn.model_selection import train_test_split\n",
    "config = tf.ConfigProto()\n",
    "from sklearn.svm import SVC\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "with tf.Session(config = config) as s:\n",
    "\n",
    "    import numpy\n",
    "    from keras.datasets import mnist\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import Dropout\n",
    "    from keras.layers import Flatten\n",
    "    from keras.layers.convolutional import Conv2D\n",
    "    from keras.layers.convolutional import MaxPooling2D\n",
    "    from keras.utils import np_utils\n",
    "    from keras import backend as K\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from keras.models import model_from_json\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    K.set_image_dim_ordering('th')\n",
    "    \n",
    "    seed = 7\n",
    "    numpy.random.seed(seed)\n",
    "    \n",
    "    dataset = numpy.loadtxt(\"out_24.txt\",delimiter=\",\")\n",
    "    print('loaded training dataset')\n",
    "    dim = 100*200\n",
    "    count=0\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    X.clear()\n",
    "    Y.clear()\n",
    "    for i in dataset:\n",
    "        X.append([])\n",
    "        for j in range(dim):\n",
    "            X[count].append(i[j])\n",
    "        value=int(i[dim])\n",
    "        if(count<=240):\n",
    "            if(value>=1000):\n",
    "                Y.append(int(value/100))\n",
    "            elif(value>=100):\n",
    "                Y.append(int(value/10))\n",
    "            else :\n",
    "                Y.append(int(value/10))\n",
    "        else :\n",
    "            if(value>=100):\n",
    "                Y.append(int(value/100))\n",
    "            else :\n",
    "                Y.append(int(value/10))\n",
    "        count+=1\n",
    "   # X_train, X_test, y_train , y_test = train_test_split(X, Y,shuffle = True,test_size = 0.1)\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "        #X1.append((X[row]))\n",
    "        #print(X_train)\n",
    "        #Y1.append((float)(Y[row]))\n",
    "    dataset = numpy.loadtxt(\"out_6.txt\",delimiter=\",\")\n",
    "    y_test=[]\n",
    "    X_test=[]\n",
    "    count=0\n",
    "    for i in dataset:\n",
    "        X_test.append([])\n",
    "        for j in range(dim):\n",
    "            X_test[count].append(i[j])\n",
    "        value=int(i[dim])\n",
    "        if(count<=60):\n",
    "            if(value>=1000):\n",
    "                y_test.append(int(value/100))\n",
    "            elif(value>=100):\n",
    "                y_test.append(int(value/10))\n",
    "            else :\n",
    "                y_test.append(int(value/10))\n",
    "        else :\n",
    "            if(value>=100):\n",
    "                y_test.append(int(value/100))\n",
    "            else :\n",
    "                y_test.append(int(value/10))\n",
    "        count+=1\n",
    "    for i in range(20):\n",
    "        clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(35,i+25), random_state=1)\n",
    "\n",
    "\n",
    "        clf.fit(X,Y)\n",
    "        count=0\n",
    "        prediction = clf.predict(X_test)\n",
    "        for i in range(len(prediction)):\n",
    "            if(prediction[i]==y_test[i]):\n",
    "                count+=1\n",
    "            #print(str(prediction[i])+\" \"+str(y_test[i])+\"\\n\")\n",
    "        #print(X_train.shape , X_test.shape)\n",
    "       # X_train = X_train.reshape(X_train.shape[0], 1, 100, 200).astype('float32')\n",
    "        #X_test = X_test.reshape(X_test.shape[0], 1, 100, 200).astype('float32')\n",
    "        print(str(count)+\" \"+str(len(prediction)))\n",
    "        print((count/len(prediction)))\n",
    "\n",
    "        #yy = y_test\n",
    "        #y_train = np_utils.to_categorical(y_train)\n",
    "       # y_test = np_utils.to_categorical(y_test)\n",
    "        #num_classes = y_test.shape[1]\n",
    "       # print(num_classes)\n",
    "    \n",
    "    \n",
    "    #print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training dataset\n",
      "14 87\n",
      "70 87\n",
      "78 87\n",
      "82 87\n",
      "82 87\n",
      "79 87\n",
      "81 87\n",
      "82 87\n",
      "82 87\n",
      "82 87\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Nov 16 01:29:58 2017\n",
    "\n",
    "@author: User\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from sklearn.neural_network import MLPClassifier   \n",
    "from sklearn.model_selection import train_test_split\n",
    "config = tf.ConfigProto()\n",
    "from sklearn.svm import SVC\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "with tf.Session(config = config) as s:\n",
    "\n",
    "    import numpy\n",
    "    from keras.datasets import mnist\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import Dropout\n",
    "    from keras.layers import Flatten\n",
    "    from keras.layers.convolutional import Conv2D\n",
    "    from keras.layers.convolutional import MaxPooling2D\n",
    "    from keras.utils import np_utils\n",
    "    from keras import backend as K\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from keras.models import model_from_json\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    K.set_image_dim_ordering('th')\n",
    "    \n",
    "\n",
    " \n",
    "    \n",
    "    dataset = numpy.loadtxt(\"out_24.txt\",delimiter=\",\")\n",
    "    print('loaded training dataset')\n",
    "    dim = 100*200\n",
    "    count=0\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for i in dataset:\n",
    "        X.append([])\n",
    "        for j in range(dim):\n",
    "            X[count].append(i[j])\n",
    "        value=int(i[dim])\n",
    "        if(count<=240):\n",
    "            if(value>=1000):\n",
    "                Y.append(int(value/100))\n",
    "            elif(value>=100):\n",
    "                Y.append(int(value/10))\n",
    "            else :\n",
    "                Y.append(int(value/10))\n",
    "        else :\n",
    "            if(value>=100):\n",
    "                Y.append(int(value/100))\n",
    "            else :\n",
    "                Y.append(int(value/10))\n",
    "        count+=1\n",
    "   # X_train, X_test, y_train , y_test = train_test_split(X, Y,shuffle = True,test_size = 0.1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "        #X1.append((X[row]))\n",
    "        #print(X_train)\n",
    "        #Y1.append((float)(Y[row]))\n",
    "    for i in range(10): \n",
    "        clf= SVC(kernel = 'rbf', C = i+1).fit(X_train, y_train)\n",
    "        prediction = clf.predict(X_test)\n",
    "        count=0\n",
    "        for i in range(len(prediction)):\n",
    "            if(prediction[i]==y_test[i]):\n",
    "                count+=1\n",
    "            #print(str(prediction[i])+\" \"+str(y_test[i])+\"\\n\")\n",
    "        #print(X_train.shape , X_test.shape)\n",
    "       # X_train = X_train.reshape(X_train.shape[0], 1, 100, 200).astype('float32')\n",
    "        #X_test = X_test.reshape(X_test.shape[0], 1, 100, 200).astype('float32')\n",
    "        print(str(count)+\" \"+str(len(prediction)))\n",
    "\n",
    "        #yy = y_test\n",
    "        #y_train = np_utils.to_categorical(y_train)\n",
    "       # y_test = np_utils.to_categorical(y_test)\n",
    "        #num_classes = y_test.shape[1]\n",
    "       # print(num_classes)\n",
    "    \n",
    "    \n",
    "    #print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression On out_6 Data with out_24 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy\n",
    "reg = LinearRegression()\n",
    "dataset = numpy.loadtxt(\"out_24.txt\",delimiter=\",\")\n",
    "print('loaded training dataset')\n",
    "dim = 100*200\n",
    "count=0\n",
    "X=[]\n",
    "Y=[]\n",
    "X.clear()\n",
    "Y.clear()\n",
    "for i in dataset:\n",
    "    X.append([])\n",
    "    for j in range(dim):\n",
    "        X[count].append(i[j])\n",
    "    value=int(i[dim])\n",
    "    if(count<=240):\n",
    "        if(value>=1000):\n",
    "            Y.append(int(value/100))\n",
    "        elif(value>=100):\n",
    "            Y.append(int(value/10))\n",
    "        else :\n",
    "            Y.append(int(value/10))\n",
    "    else :\n",
    "        if(value>=100):\n",
    "            Y.append(int(value/100))\n",
    "        else :\n",
    "            Y.append(int(value/10))\n",
    "dataset = numpy.loadtxt(\"out_6.txt\",delimiter=\",\")\n",
    "y_test=[]\n",
    "X_test=[]\n",
    "count=0\n",
    "for i in dataset:\n",
    "    X_test.append([])\n",
    "    for j in range(dim):\n",
    "        X_test[count].append(i[j])\n",
    "    value=int(i[dim])\n",
    "    if(count<=60):\n",
    "        if(value>=1000):\n",
    "            y_test.append(int(value/100))\n",
    "        elif(value>=100):\n",
    "            y_test.append(int(value/10))\n",
    "        else :\n",
    "            y_test.append(int(value/10))\n",
    "    else :\n",
    "        if(value>=100):\n",
    "            y_test.append(int(value/100))\n",
    "        else :\n",
    "            y_test.append(int(value/10))\n",
    "    count+=1\n",
    "reg.fit(X,Y)\n",
    "acc=reg.score(X_test,y_test)\n",
    "#print(\"Accuracy %.2f\" % round(acc*100,2)+' %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
