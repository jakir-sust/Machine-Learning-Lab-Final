{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apartment Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mpl_toolkits\n",
    "import timeit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21613\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"kc_house_data.csv\")\n",
    "#data=data[0:1000]\n",
    "print(len(data))\n",
    "#data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\software\\install\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 71.56 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "reg = LinearRegression()\n",
    "labels = data['price']\n",
    "train1 = data.drop(['price','date','id'],axis=1)\n",
    "\n",
    "\n",
    "x_train , x_test , y_train , y_test = train_test_split(train1 , labels , test_size = 0.20,random_state =2)\n",
    "\n",
    "(reg.fit(x_train,y_train))\n",
    "acc=reg.score(x_test,y_test)\n",
    "print(\"Accuracy %.2f\" % round(acc*100,2)+' %')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 88.64 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "reg = ensemble.GradientBoostingRegressor(n_estimators = 100, max_depth = 5, min_samples_split = 2,\n",
    "          learning_rate = 0.1, loss = 'ls')\n",
    "labels = data['price']\n",
    "train1 = data.drop(['price','date','id'],axis=1)\n",
    "\n",
    "\n",
    "x_train , x_test , y_train , y_test = train_test_split(train1 , labels , test_size = 0.20,random_state =2)\n",
    "\n",
    "(reg.fit(x_train,y_train))\n",
    "acc=reg.score(x_test,y_test)\n",
    "print(\"Accuracy %.2f\" % round(acc*100,2)+' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Accuracy 0.51 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "reg = LogisticRegression()\n",
    "labels = data['price']\n",
    "train1 = data.drop(['price','date','id'],axis=1)\n",
    "\n",
    "\n",
    "x_train , x_test , y_train , y_test = train_test_split(train1 , labels , test_size = 0.10,random_state =2)\n",
    "\n",
    "print(reg.fit(x_train,y_train))\n",
    "acc=reg.score(x_test,y_test)\n",
    "print(\"Accuracy %.2f\" % round(acc*100,2)+' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "7.160294166865619\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "\n",
    "#Your statements here\n",
    "\n",
    "\n",
    "#model = LogisticRegression()\n",
    "#NB = GaussianNB()\n",
    "LR = LogisticRegression()\n",
    "labels = data['price']\n",
    "train1 = data.drop(['price','date','id'],axis=1)\n",
    "\n",
    "\n",
    "x_train , x_test , y_train , y_test = train_test_split(train1 , labels , test_size = 0.10,random_state =2)\n",
    "# train1.describe()\n",
    "# print(x_train)\n",
    "#print(y_train)\n",
    "print(LR.fit(x_train,y_train))\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print (stop - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 2.04 %\n",
      "21613\n"
     ]
    }
   ],
   "source": [
    "acc=LR.score(x_test,y_test)\n",
    "print(\"Accuracy %.2f\" % round(acc*100,2)+' %')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "\n",
    "#Your statements here\n",
    "\n",
    "\n",
    "#model = LogisticRegression()\n",
    "#NB = GaussianNB()\n",
    "SVM=svm.SVC(kernel='poly', gamma=1)\n",
    "labels = data['price']\n",
    "train1 = data.drop(['price','date','id'],axis=1)\n",
    "\n",
    "\n",
    "x_train , x_test , y_train , y_test = train_test_split(train1 , labels , test_size = 0.10,random_state =2)\n",
    "# train1.describe()\n",
    "# print(x_train)\n",
    "#print(y_train)\n",
    "print(SVM.fit(x_train,y_train) )\n",
    "\n",
    "acc=SVM.score(x_test,y_test)\n",
    "print(\"Accuracy %.2f\" % round(acc*100,2)+' %')\n",
    "print(len(data))\n",
    "\n",
    "#prediction = SVM.predict([x_test[1]])\n",
    "#print(prediction,y_test)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print (stop - start) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Accuracy 0.00 %\n",
      "1000\n",
      "0.16025088078254157\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import csv\n",
    "\n",
    "  \n",
    "start = timeit.default_timer()\n",
    "\n",
    "#Your statements here\n",
    "\n",
    "\n",
    "#model = LogisticRegression()\n",
    "#NB = GaussianNB()\n",
    "# SVM=svm.SVC(kernel='poly', gamma=1)\n",
    "D_tree = tree.DecisionTreeClassifier() \n",
    "\n",
    "labels = data['price']\n",
    "train1 = data.drop(['price','date','id'],axis=1)\n",
    "\n",
    "\n",
    "x_train , x_test , y_train , y_test = train_test_split(train1 , labels , test_size = 0.10,random_state =2)\n",
    "# train1.describe()\n",
    "# print(x_train)\n",
    "#print(y_train)\n",
    "print(D_tree.fit(x_train,y_train) )\n",
    "\n",
    "acc=D_tree.score(x_test,y_test)\n",
    "print(\"Accuracy %.2f\" % round(acc*100,2)+' %')\n",
    "print(len(data))\n",
    "\n",
    "#prediction = SVM.predict([x_test[1]])\n",
    "#print(prediction,y_test)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print (stop - start) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K nearest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=500, p=2,\n",
      "           weights='uniform')\n",
      "Accuracy 1.30 %\n",
      "21613\n",
      "11.919266992576013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import csv\n",
    "\n",
    "  \n",
    "start = timeit.default_timer()\n",
    "\n",
    "#Your statements here\n",
    "neigh = KNeighborsClassifier(n_neighbors=500)\n",
    "#neigh.fit(X, y) \n",
    "\n",
    "#model = LogisticRegression()\n",
    "#NB = GaussianNB()\n",
    "# SVM=svm.SVC(kernel='poly', gamma=1)\n",
    "KNN = NearestCentroid()\n",
    "\n",
    "labels = data['price']\n",
    "train1 = data.drop(['price','date','id'],axis=1)\n",
    "\n",
    "\n",
    "x_train , x_test , y_train , y_test = train_test_split(train1 , labels , test_size = 0.10,random_state =2)\n",
    "# train1.describe()\n",
    "# print(x_train)\n",
    "#print(y_train)\n",
    "print(neigh.fit(x_train,y_train) )\n",
    "\n",
    "acc=neigh.score(x_test,y_test)\n",
    "print(\"Accuracy %.2f\" % round(acc*100,2)+' %')\n",
    "print(len(data))\n",
    "\n",
    "#print(neigh.predict_proba([[x_test(1)]))\n",
    "#predictio = KNN.predict([[x_test[1]]])\n",
    "#print(predictio)\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print (stop - start) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
